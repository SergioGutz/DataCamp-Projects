{"cells":[{"source":"![Cartoon of telecom customers](IMG_8811.png)\n","metadata":{},"id":"cdd466f9-a72a-44df-9e00-6926a97a4923","cell_type":"markdown"},{"source":"The telecommunications (telecom) sector in India is rapidly changing, with more and more telecom businesses being created and many customers deciding to switch between providers. \"Churn\" refers to the process where customers or subscribers stop using a company's services or products. Understanding the factors that influence keeping a customer as a client in predicting churn is crucial for telecom companies to enhance their service quality and customer satisfaction. As the data scientist on this project, you aim to explore the intricate dynamics of customer behavior and demographics in the Indian telecom sector in predicting customer churn, utilizing two comprehensive datasets from four major telecom partners: Airtel, Reliance Jio, Vodafone, and BSNL:\n\n- `telecom_demographics.csv` contains information related to Indian customer demographics:\n\n| Variable             | Description                                      |\n|----------------------|--------------------------------------------------|\n| `customer_id `         | Unique identifier for each customer.             |\n| `telecom_partner `     | The telecom partner associated with the customer.|\n| `gender `              | The gender of the customer.                      |\n| `age `                 | The age of the customer.                         |\n| `state`                | The Indian state in which the customer is located.|\n| `city`                 | The city in which the customer is located.       |\n| `pincode`              | The pincode of the customer's location.          |\n| `registration_event` | When the customer registered with the telecom partner.|\n| `num_dependents`      | The number of dependents (e.g., children) the customer has.|\n| `estimated_salary`     | The customer's estimated salary.                 |\n\n- `telecom_usage` contains information about the usage patterns of Indian customers:\n\n| Variable   | Description                                                  |\n|------------|--------------------------------------------------------------|\n| `customer_id` | Unique identifier for each customer.                         |\n| `calls_made` | The number of calls made by the customer.                    |\n| `sms_sent`   | The number of SMS messages sent by the customer.             |\n| `data_used`  | The amount of data used by the customer.                     |\n| `churn`    | Binary variable indicating whether the customer has churned or not (1 = churned, 0 = not churned).|\n","metadata":{},"id":"dafa483a-e084-4ba8-9236-5c0468364e0d","cell_type":"markdown"},{"source":"# Import libraries and methods/functions\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Start your code here!\n\n# Load the two CSV files into separate DataFrames. Merge them into a DataFrame named churn_df\ndemo_df = pd.read_csv('telecom_demographics.csv')\n\nusage_df = pd.read_csv('telecom_usage.csv')\n\nchurn_df = demo_df.merge(usage_df, on = 'customer_id')\n\nchurn_df.info()\nchurn_df.head()","metadata":{"executionCancelledAt":null,"executionTime":59,"lastExecutedAt":1722269338798,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import libraries and methods/functions\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Start your code here!\n\n# Load the two CSV files into separate DataFrames. Merge them into a DataFrame named churn_df\ndemo_df = pd.read_csv('telecom_demographics.csv')\n\nusage_df = pd.read_csv('telecom_usage.csv')\n\nchurn_df = demo_df.merge(usage_df, on = 'customer_id')\n\nchurn_df.info()\nchurn_df.head()","lastExecutedByKernel":"afa5eb5b-fcb7-4b4a-b349-fbbe1f3a82b8","outputsMetadata":{"0":{"height":458,"type":"stream"},"1":{"height":213,"type":"dataFrame"}}},"id":"95efd3c7-a48a-49c2-9df6-36f078de3b38","cell_type":"code","execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 6500 entries, 0 to 6499\nData columns (total 14 columns):\n #   Column              Non-Null Count  Dtype \n---  ------              --------------  ----- \n 0   customer_id         6500 non-null   int64 \n 1   telecom_partner     6500 non-null   object\n 2   gender              6500 non-null   object\n 3   age                 6500 non-null   int64 \n 4   state               6500 non-null   object\n 5   city                6500 non-null   object\n 6   pincode             6500 non-null   int64 \n 7   registration_event  6500 non-null   object\n 8   num_dependents      6500 non-null   int64 \n 9   estimated_salary    6500 non-null   int64 \n 10  calls_made          6500 non-null   int64 \n 11  sms_sent            6500 non-null   int64 \n 12  data_used           6500 non-null   int64 \n 13  churn               6500 non-null   int64 \ndtypes: int64(9), object(5)\nmemory usage: 761.7+ KB\n"},{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"customer_id","type":"integer"},{"name":"telecom_partner","type":"string"},{"name":"gender","type":"string"},{"name":"age","type":"integer"},{"name":"state","type":"string"},{"name":"city","type":"string"},{"name":"pincode","type":"integer"},{"name":"registration_event","type":"string"},{"name":"num_dependents","type":"integer"},{"name":"estimated_salary","type":"integer"},{"name":"calls_made","type":"integer"},{"name":"sms_sent","type":"integer"},{"name":"data_used","type":"integer"},{"name":"churn","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4],"customer_id":[15169,149207,148119,187288,14016],"telecom_partner":["Airtel","Airtel","Airtel","Reliance Jio","Vodafone"],"gender":["F","F","F","M","M"],"age":[26,74,54,29,45],"state":["Himachal Pradesh","Uttarakhand","Jharkhand","Bihar","Nagaland"],"city":["Delhi","Hyderabad","Chennai","Hyderabad","Bangalore"],"pincode":[667173,313997,549925,230636,188036],"registration_event":["2020-03-16","2022-01-16","2022-01-11","2022-07-26","2020-03-11"],"num_dependents":[4,0,2,3,4],"estimated_salary":[85979,69445,75949,34272,34157],"calls_made":[75,35,70,95,66],"sms_sent":[21,38,47,32,23],"data_used":[4532,723,4688,10241,5246],"churn":[1,1,1,1,1]}},"total_rows":5,"truncation_type":null},"text/plain":"   customer_id telecom_partner gender  ...  sms_sent data_used churn\n0        15169          Airtel      F  ...        21      4532     1\n1       149207          Airtel      F  ...        38       723     1\n2       148119          Airtel      F  ...        47      4688     1\n3       187288    Reliance Jio      M  ...        32     10241     1\n4        14016        Vodafone      M  ...        23      5246     1\n\n[5 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>telecom_partner</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>state</th>\n      <th>city</th>\n      <th>pincode</th>\n      <th>registration_event</th>\n      <th>num_dependents</th>\n      <th>estimated_salary</th>\n      <th>calls_made</th>\n      <th>sms_sent</th>\n      <th>data_used</th>\n      <th>churn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15169</td>\n      <td>Airtel</td>\n      <td>F</td>\n      <td>26</td>\n      <td>Himachal Pradesh</td>\n      <td>Delhi</td>\n      <td>667173</td>\n      <td>2020-03-16</td>\n      <td>4</td>\n      <td>85979</td>\n      <td>75</td>\n      <td>21</td>\n      <td>4532</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>149207</td>\n      <td>Airtel</td>\n      <td>F</td>\n      <td>74</td>\n      <td>Uttarakhand</td>\n      <td>Hyderabad</td>\n      <td>313997</td>\n      <td>2022-01-16</td>\n      <td>0</td>\n      <td>69445</td>\n      <td>35</td>\n      <td>38</td>\n      <td>723</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>148119</td>\n      <td>Airtel</td>\n      <td>F</td>\n      <td>54</td>\n      <td>Jharkhand</td>\n      <td>Chennai</td>\n      <td>549925</td>\n      <td>2022-01-11</td>\n      <td>2</td>\n      <td>75949</td>\n      <td>70</td>\n      <td>47</td>\n      <td>4688</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>187288</td>\n      <td>Reliance Jio</td>\n      <td>M</td>\n      <td>29</td>\n      <td>Bihar</td>\n      <td>Hyderabad</td>\n      <td>230636</td>\n      <td>2022-07-26</td>\n      <td>3</td>\n      <td>34272</td>\n      <td>95</td>\n      <td>32</td>\n      <td>10241</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14016</td>\n      <td>Vodafone</td>\n      <td>M</td>\n      <td>45</td>\n      <td>Nagaland</td>\n      <td>Bangalore</td>\n      <td>188036</td>\n      <td>2020-03-11</td>\n      <td>4</td>\n      <td>34157</td>\n      <td>66</td>\n      <td>23</td>\n      <td>5246</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":39}]},{"source":"# Calculate and print churn rate\nchurn_count = churn_df.loc[churn_df['churn']==1, 'churn'].count()\n\nchurn_rate = churn_count/len(churn_df)\n\nprint(churn_rate)","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1722269338845,"lastExecutedByKernel":"afa5eb5b-fcb7-4b4a-b349-fbbe1f3a82b8","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Calculate and print churn rate\nchurn_count = churn_df.loc[churn_df['churn']==1, 'churn'].count()\n\nchurn_rate = churn_count/len(churn_df)\n\nprint(churn_rate)","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"617010c4-257f-488c-87ef-4b1a6ad13a09","outputs":[{"output_type":"stream","name":"stdout","text":"0.20046153846153847\n"}],"execution_count":40},{"source":"# Identify the categorical variables in churn_df\nX_cat_columns = churn_df.drop(['customer_id', 'churn'], axis=1).select_dtypes(include=['object']).columns.tolist()\n\n# Convert categorical features in churn_df into features_scaled\nenc = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\nX_cat_encoded = enc.fit_transform(churn_df[X_cat_columns])\nX_cat_encoded_df = pd.DataFrame(X_cat_encoded, columns=enc.get_feature_names_out(X_cat_columns))\n\n# Select remaining numerical variables in churn_df\nX_num_columns = churn_df.drop(['customer_id', 'churn'], axis=1).select_dtypes(include=['int64']).columns.tolist()\nX_num_df = churn_df[X_num_columns]\n\n# Merge categorical and numerical variables in churn_df before scaling\nfeatures_df = X_num_df.merge(X_cat_encoded_df, left_index=True, right_index=True)\n\nprint(features_df)","metadata":{"executionCancelledAt":null,"executionTime":175,"lastExecutedAt":1722269339020,"lastExecutedByKernel":"afa5eb5b-fcb7-4b4a-b349-fbbe1f3a82b8","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Identify the categorical variables in churn_df\nX_cat_columns = churn_df.drop(['customer_id', 'churn'], axis=1).select_dtypes(include=['object']).columns.tolist()\n\n# Convert categorical features in churn_df into features_scaled\nenc = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\nX_cat_encoded = enc.fit_transform(churn_df[X_cat_columns])\nX_cat_encoded_df = pd.DataFrame(X_cat_encoded, columns=enc.get_feature_names_out(X_cat_columns))\n\n# Select remaining numerical variables in churn_df\nX_num_columns = churn_df.drop(['customer_id', 'churn'], axis=1).select_dtypes(include=['int64']).columns.tolist()\nX_num_df = churn_df[X_num_columns]\n\n# Merge categorical and numerical variables in churn_df before scaling\nfeatures_df = X_num_df.merge(X_cat_encoded_df, left_index=True, right_index=True)\n\nprint(features_df)","outputsMetadata":{"0":{"height":311,"type":"stream"}}},"cell_type":"code","id":"7aa04cdf-1b75-4379-a1e1-799552ab46c9","outputs":[{"output_type":"stream","name":"stdout","text":"      age  ...  registration_event_2023-05-03\n0      26  ...                            0.0\n1      74  ...                            0.0\n2      54  ...                            0.0\n3      29  ...                            0.0\n4      45  ...                            0.0\n...   ...  ...                            ...\n6495   54  ...                            0.0\n6496   69  ...                            0.0\n6497   19  ...                            0.0\n6498   26  ...                            0.0\n6499   19  ...                            0.0\n\n[6500 rows x 1263 columns]\n"}],"execution_count":41},{"source":"# Perform feature scaling separating the appropriate features and scale them\nscr = StandardScaler()\n\n# Define your scaled features and target variable for the churn prediction model\nfeatures_scaled = scr.fit_transform(features_df)\n\ntarget = churn_df['churn']\n\nprint(features_scaled)","metadata":{"executionCancelledAt":null,"executionTime":110,"lastExecutedAt":1722269339130,"lastExecutedByKernel":"afa5eb5b-fcb7-4b4a-b349-fbbe1f3a82b8","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Perform feature scaling separating the appropriate features and scale them\nscr = StandardScaler()\n\n# Define your scaled features and target variable for the churn prediction model\nfeatures_scaled = scr.fit_transform(features_df)\n\ntarget = churn_df['churn']\n\nprint(features_scaled)","outputsMetadata":{"0":{"height":290,"type":"stream"}}},"cell_type":"code","id":"a3cbfbec-41df-45e9-be37-850023990ea9","outputs":[{"output_type":"stream","name":"stdout","text":"[[-1.22296979  0.45493603  1.43653887 ... -0.04117252 -0.03283419\n  -0.02774568]\n [ 1.6963038  -0.90419473 -1.41134604 ... -0.04117252 -0.03283419\n  -0.02774568]\n [ 0.47993981  0.00372937  0.01259641 ... -0.04117252 -0.03283419\n  -0.02774568]\n ...\n [-1.64869719 -1.5268359  -1.41134604 ... -0.04117252 -0.03283419\n  -0.02774568]\n [-1.22296979  0.89731466  0.72456764 ... -0.04117252 -0.03283419\n  -0.02774568]\n [-1.64869719  1.42210486  0.72456764 ... -0.04117252 -0.03283419\n  -0.02774568]]\n"}],"execution_count":42},{"source":"# Split the processed data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.2, random_state=42)\n\nseed = 42\n\n# Train Logistic Regression and Random Forest Classifier models, setting a random seed of 42. Store model predictions in logreg_pred and rf_pred\nlogreg = LogisticRegression(random_state=seed)\nlogreg.fit(X_train, y_train)\nlogreg_pred = logreg.predict(X_test)\nprint(confusion_matrix(y_test, logreg_pred))\nprint(classification_report(y_test, logreg_pred))\n\nlogreg_score = accuracy_score(y_test, logreg_pred)\n\nrf = RandomForestClassifier(random_state=seed)\nrf.fit(X_train, y_train)\nrf_pred = rf.predict(X_test)\n\nprint(confusion_matrix(y_test, rf_pred))\nprint(classification_report(y_test, rf_pred))\n\nrf_score = accuracy_score(y_test, rf_pred)\n\n# Assign the model's name with higher accuracy (\"LogisticRegression\" or \"RandomForest\") to higher_accuracy\nhigher_accuracy = np.where(logreg_score > rf_score, 'LogisticRegression', 'RandomForest')","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":479,"type":"stream"}}},"cell_type":"code","id":"2e4c80b1-5cb2-41a4-98b7-5391129bc1fc","outputs":[{"output_type":"stream","name":"stdout","text":"[[920 107]\n [245  28]]\n              precision    recall  f1-score   support\n\n           0       0.79      0.90      0.84      1027\n           1       0.21      0.10      0.14       273\n\n    accuracy                           0.73      1300\n   macro avg       0.50      0.50      0.49      1300\nweighted avg       0.67      0.73      0.69      1300\n\n[[1026    1]\n [ 273    0]]\n              precision    recall  f1-score   support\n\n           0       0.79      1.00      0.88      1027\n           1       0.00      0.00      0.00       273\n\n    accuracy                           0.79      1300\n   macro avg       0.39      0.50      0.44      1300\nweighted avg       0.62      0.79      0.70      1300\n\n"}],"execution_count":43}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}